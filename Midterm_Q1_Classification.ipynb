{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error - SVMWithSGD = 0.381551168282\n",
      "Testing Error - SVMWithSGD = 0.382834895793\n",
      "Training Error - Logistic Regression = 0.40553141477\n",
      "Testing Error - Logistic Regression = 0.408015030604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/IPython/kernel/__main__.py:34: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "import plotly.plotly as py\n",
    "from pyspark.mllib.stat import Statistics\n",
    "import numpy as np\n",
    "py.sign_in('harshitshah', 'rdckn6jnj9')\n",
    "from plotly.graph_objs import *\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib\n",
    "from pyspark.ml.feature import Normalizer, StandardScaler\n",
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "\n",
    "#read data into pandas dataframe\n",
    "df = pd.read_csv('YearPredictionMSD.txt')\n",
    "df.columns = ['year','c1','c2','c3','c4','c5','c6','c7','c8','c9','c10','c11','c12','c13','c14','c15','c16','c17','c18','c19','c20','c21','c22','c23','c24','c25','c26','c27','c28','c29','c30','c31','c32','c33','c34','c35','c36','c37','c38','c39','c40','c41','c42','c43','c44','c45','c46','c47','c48','c49','c50','c51','c52','c53','c54','c55','c56','c57','c58','c59','c60','c61','c62','c63','c64','c65','c66','c67','c68','c69','c70','c71','c72','c73','c74','c75','c76','c77','c78','c79','c80','c81','c82','c83','c84','c85','c86','c87','c88','c89','c90']\n",
    "\n",
    "#Statistics\n",
    "df_sample = df.sample(100)\n",
    "print df_sample.describe()\n",
    "\n",
    "#histogram and box-plot for year\n",
    "x0 = df['year']\n",
    "trace = Data([Histogram(x=x0, histnorm='count', name='Year')])\n",
    "trace0 = Box(x=x0, , name='Year_Boxplot')\n",
    "data = Data([trace0])\n",
    "data1 = Data([trace])\n",
    "plot_url2 = py.plot(data1, filename='basic-histogram')\n",
    "plot_url = py.plot(data, filename='basic-box-plot')\n",
    "\n",
    "#backup year column as a new dataframe\n",
    "df_year = df['year']\n",
    "\n",
    "#drop year column\n",
    "df.drop(df.columns[[0]], axis=1, inplace=True)\n",
    "\n",
    "#normalize (z-score)\n",
    "df_norm = (df - df.mean())/df.std()\n",
    "\n",
    "#convert year values to binary    \n",
    "df_year[df_year < 1965] = 0\n",
    "df_year[df_year >= 1965] = 1\n",
    "\n",
    "#append to main dataframe\n",
    "df_norm['year'] = df_year\n",
    "\n",
    "#split the data into train and test\n",
    "df_train = df_norm[:463715]\n",
    "df_test = df_norm[463716:515345]\n",
    "\n",
    "#write dataframe to csv\n",
    "df_train.to_csv('df_train_Q1.csv',header = False)\n",
    "df_test.to_csv('df_test_Q1.csv',header = False)\n",
    "\n",
    "#defining a function to split values\n",
    "def parsePoint(line):\n",
    "    values = [float(x) for x in line.split(',')]\n",
    "    return LabeledPoint(values[91], values[1:90])\n",
    "\n",
    "#reading csv file into rdd\n",
    "rdd_train = sc.textFile(\"df_train_Q1.csv\")\n",
    "rdd_test = sc.textFile(\"df_test_Q1.csv\")\n",
    "\n",
    "#parsing data\n",
    "parsedData_train = rdd_train.map(parsePoint)\n",
    "parsedData_test = rdd_test.map(parsePoint)\n",
    "\n",
    "#run SVMWithSGD\n",
    "model = SVMWithSGD.train(parsedData_train, iterations=100)\n",
    "\n",
    "labelsAndPreds = parsedData_train.map(lambda p: (p.label, model.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(parsedData_train.count())\n",
    "print(\"Training Error - SVMWithSGD = \" + str(trainErr))\n",
    "\n",
    "labelsAndPreds1 = parsedData_test.map(lambda p: (p.label, model.predict(p.features)))\n",
    "testErr = labelsAndPreds1.filter(lambda (v, p): v != p).count() / float(parsedData_test.count())\n",
    "print(\"Testing Error - SVMWithSGD = \" + str(testErr))\n",
    "\n",
    "\n",
    "#run LogisticRegressionWithLBFGS\n",
    "model_Log = LogisticRegressionWithLBFGS.train(parsedData_train, iterations=100)\n",
    "\n",
    "# Evaluating the model on training data\n",
    "labelsAndPreds2 = parsedData_train.map(lambda p: (p.label, model_Log.predict(p.features)))\n",
    "trainErr1 = labelsAndPreds2.filter(lambda (v, p): v != p).count() / float(parsedData_train.count())\n",
    "print(\"Training Error - Logistic Regression = \" + str(trainErr1))\n",
    "\n",
    "labelsAndPreds3 = parsedData_test.map(lambda p: (p.label, model_Log.predict(p.features)))\n",
    "testErr1 = labelsAndPreds3.filter(lambda (v, p): v != p).count() / float(parsedData_test.count())\n",
    "print(\"Testing Error - Logistic Regression = \" + str(testErr1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
